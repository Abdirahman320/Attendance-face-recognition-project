{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e455a4c3-f079-432b-bf95-4bcbf0f920dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Initialize ArcFace pre-trained model (antelopev2)\n",
    "app = FaceAnalysis(name='antelopev2')\n",
    "app.prepare(ctx_id=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa769e9-c7a8-406b-a310-b0d840701304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "\n",
    "    # Original image\n",
    "    augmented_images.append(image)\n",
    "\n",
    "    # Horizontal flip\n",
    "    flipped = cv2.flip(image, 1)\n",
    "    augmented_images.append(flipped)\n",
    "\n",
    "    # Rotation: Â±15 degrees\n",
    "    for angle in [-15, 15]:\n",
    "        h, w = image.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "        augmented_images.append(rotated)\n",
    "\n",
    "    # Brightness adjustments\n",
    "    for beta in [-30, 30]:  # darker and brighter\n",
    "        bright_img = cv2.convertScaleAbs(image, alpha=1, beta=beta)\n",
    "        augmented_images.append(bright_img)\n",
    "\n",
    "    return augmented_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f4cd818-fd9d-43b1-8fc7-3f242e1ba3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_fallback(face_img):\n",
    "    if face_img.shape[2] == 3:\n",
    "        face_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        face_rgb = face_img\n",
    "\n",
    "    face_norm = face_rgb.astype(np.float32) / 255.0\n",
    "    face_norm = np.transpose(face_norm, (2, 0, 1))  # change HWC to CHW => (3,112,112)\n",
    "    input_imgs = np.expand_dims(face_norm, axis=0).astype(np.float32)  # (1,3,112,112)\n",
    "    # Directly run ONNX model session\n",
    "    embedding = app.models['recognition'].session.run(\n",
    "        None, {app.models['recognition'].input_name: input_imgs}\n",
    "    )[0]\n",
    "\n",
    "    embedding = embedding.flatten()\n",
    "\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a60b70-a875-4d3a-ba81-58ac9a5f35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset_and_extract_embeddings(data_dir):\n",
    "    \"\"\"\n",
    "    Loads images from subfolders of `data_dir` (each folder is a class label).\n",
    "    Extracts embeddings using ArcFace with fallback method.\n",
    "    Returns embeddings array, labels array, and class names list.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    class_to_idx = {cls_name: idx for idx, cls_name in enumerate(class_names)}\n",
    "\n",
    "    for cls_name in class_names:\n",
    "        cls_folder = os.path.join(data_dir, cls_name)\n",
    "        if not os.path.isdir(cls_folder):\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(cls_folder):\n",
    "            img_path = os.path.join(cls_folder, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning: failed to load image {img_path}\")\n",
    "                continue\n",
    "\n",
    "            emb = get_embedding_fallback(img)\n",
    "            embeddings.append(emb)\n",
    "            labels.append(class_to_idx[cls_name])\n",
    "            augmented_imgs = augment_image(img)\n",
    "            for aug_img in augmented_imgs:\n",
    "              emb = get_embedding(aug_img)\n",
    "              embeddings.append(emb)\n",
    "              labels.append(class_to_idx[cls_name])\n",
    "\n",
    "\n",
    "    return np.array(embeddings), np.array(labels), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb7a741-b17d-4918-b5da-c334d319580e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/preprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Your aligned preprocessed images folder\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m embeddings, labels, class_names \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_and_extract_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted embeddings for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(embeddings)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(class_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m, in \u001b[0;36mload_dataset_and_extract_embeddings\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     27\u001b[0m augmented_imgs \u001b[38;5;241m=\u001b[39m augment_image(img)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m aug_img \u001b[38;5;129;01min\u001b[39;00m augmented_imgs:\n\u001b[1;32m---> 29\u001b[0m   emb \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m(aug_img)\n\u001b[0;32m     30\u001b[0m   embeddings\u001b[38;5;241m.\u001b[39mappend(emb)\n\u001b[0;32m     31\u001b[0m   labels\u001b[38;5;241m.\u001b[39mappend(class_to_idx[cls_name])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/preprocessed'  # Your aligned preprocessed images folder\n",
    "embeddings, labels, class_names = load_dataset_and_extract_embeddings(data_dir)\n",
    "print(f\"Extracted embeddings for {len(embeddings)} images from {len(class_names)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4f87452c-2e87-47d5-b3c8-2ed8beaed266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM classifier on 1612 samples...\n",
      "Training complete!\n",
      "Test set accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings, labels, test_size=0.15, random_state=42, stratify=labels)\n",
    "\n",
    "print(f\"Training SVM classifier on {len(X_train)} samples...\")\n",
    "clf = SVC(kernel='linear', probability=True)  # You can tune parameters later\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Evaluate accuracy on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d46d862d-ec60-4a42-b7b2-69cf0df90d44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm_face_recognition_model_v3.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "model_filename = 'svm_face_recognition_model_v3.joblib'\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(clf, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6989f08f-ec07-4553-91a9-d01ad3912ed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm_face_recognition_model_v3.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\Face_Recognition\\env\\lib\\site-packages\\joblib\\numpy_pickle.py:749\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[0;32m    744\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m    746\u001b[0m             \u001b[38;5;66;03m# A memory-mapped array has to be mapped with the endianness\u001b[39;00m\n\u001b[0;32m    747\u001b[0m             \u001b[38;5;66;03m# it has been written with. Other arrays are coerced to the\u001b[39;00m\n\u001b[0;32m    748\u001b[0m             \u001b[38;5;66;03m# native endianness of the host system.\u001b[39;00m\n\u001b[1;32m--> 749\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m                \u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidated_mmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\Desktop\\Face_Recognition\\env\\lib\\site-packages\\joblib\\numpy_pickle.py:626\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    624\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 626\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    628\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    633\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    634\u001b[0m         )\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1579\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "model_filename = 'svm_face_recognition_model_v3.joblib'\n",
    "classifier = joblib.load(model_filename)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a5866c-fe3e-4603-ab36-7ccfd5c9fda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdirahman\\Desktop\\Face_Recognition\\env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n",
      "ArcFace model loaded and ready!\n"
     ]
    }
   ],
   "source": [
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "app = FaceAnalysis(name='antelopev2')\n",
    "app.prepare(ctx_id=-1)\n",
    "print(\"ArcFace model loaded and ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34967015-7a8f-481d-857c-0fc536a3f960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV bindings requires \"numpy\" package.\n",
      "Install it via command:\n",
      "    pip install numpy\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Face_Recognition\\env\\lib\\site-packages\\cv2\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiarray\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Initialize ArcFace with proper configuration\n",
    "app = FaceAnalysis(name='antelopev2', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "def get_proper_embedding(img):\n",
    "    \"\"\"Use ArcFace's full pipeline including detection and alignment\"\"\"\n",
    "    faces = app.get(img)\n",
    "    if not faces:\n",
    "        return None\n",
    "    return faces[0]['embedding']\n",
    "\n",
    "def predict_face_class(image_path, classifier, class_names, threshold=0.5):\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Failed to load image from {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Get embedding using ArcFace's full pipeline\n",
    "    embedding = get_proper_embedding(img)\n",
    "    if embedding is None:\n",
    "        print(\"No face detected or alignment failed!\")\n",
    "        return None\n",
    "\n",
    "    # For SVM with probability=True\n",
    "    if hasattr(classifier, \"predict_proba\"):\n",
    "        probabilities = classifier.predict_proba([embedding])[0]\n",
    "        confidence = np.max(probabilities)\n",
    "        if confidence < threshold:\n",
    "            print(f\"Predicted: Unknown (confidence: {confidence:.3f})\")\n",
    "            return \"Unknown\"\n",
    "        predicted_idx = np.argmax(probabilities)\n",
    "    \n",
    "    # For regular SVM (use decision function)\n",
    "    else:\n",
    "        distances = classifier.decision_function([embedding])[0]\n",
    "        confidence = np.max(distances)\n",
    "        if confidence < threshold:\n",
    "            print(f\"Predicted: Unknown (confidence: {confidence:.3f})\")\n",
    "            return \"Unknown\"\n",
    "        predicted_idx = np.argmax(distances)\n",
    "\n",
    "    predicted_name = class_names[predicted_idx]\n",
    "    print(f\"Predicted: {predicted_name} (confidence: {confidence:.3f})\")\n",
    "    return predicted_name\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load model and classes\n",
    "    model_path = 'svm_face_recognition_model_v3.joblib'\n",
    "    data_dir = 'data/preprocessed'\n",
    "    \n",
    "    classifier = joblib.load(model_path)\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    \n",
    "    # Test image\n",
    "    test_image = r'C:\\Users\\abdirahman\\Downloads\\img.jpeg'\n",
    "    \n",
    "    # First verify class names\n",
    "\n",
    "    \n",
    "    # Predict with lower threshold\n",
    "    predict_face_class(test_image, classifier, class_names, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe092bb3-cd84-456c-b7a7-1971f5e45628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6f54ae-5a31-4476-b861-a7c6c73e4cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdirahman\\Desktop\\Face_Recognition\\env\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\abdirahman/.insightface\\models\\antelopev2\\scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n",
      "Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# === Load trained classifier ===\n",
    "model_path = 'svm_face_recognition_model_v3.joblib'\n",
    "data_dir = 'data/preprocessed'\n",
    "classifier = joblib.load(model_path)\n",
    "class_names = sorted(os.listdir(data_dir))\n",
    "\n",
    "# === Initialize FaceAnalysis (ArcFace) ===\n",
    "app = FaceAnalysis(name='antelopev2', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# === Function to get embedding from frame ===\n",
    "def get_embedding_from_frame(frame):\n",
    "    faces = app.get(frame)\n",
    "    if not faces:\n",
    "        return None, None\n",
    "    return faces, faces[0]['embedding']\n",
    "\n",
    "# === Real-time Camera Loop ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Camera not found.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    faces = app.get(frame_rgb)\n",
    "\n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = map(int, face['bbox'])\n",
    "        embedding = face['embedding'].reshape(1, -1)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "        confidence = 0.0\n",
    "\n",
    "        if hasattr(classifier, \"predict_proba\"):\n",
    "            probs = classifier.predict_proba(embedding)[0]\n",
    "            best_idx = np.argmax(probs)\n",
    "            confidence = probs[best_idx]\n",
    "            if confidence > 0.3:\n",
    "                name = class_names[best_idx]\n",
    "        else:\n",
    "            decision = classifier.decision_function(embedding)[0]\n",
    "            best_idx = np.argmax(decision)\n",
    "            confidence = decision[best_idx]\n",
    "            if confidence > 0.3:\n",
    "                name = class_names[best_idx]\n",
    "\n",
    "        # Draw box and label\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        label = f\"{name} ({confidence:.2f})\"\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Real-Time Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0cc749-6e34-4fc2-9d15-bd9292cb0329",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the old model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msvm_face_recognition_model_v3.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Save as a new modern version\u001b[39;00m\n\u001b[0;32m      7\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(classifier, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm_face_recognition_model_v4.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\Face_Recognition\\env\\lib\\site-packages\\joblib\\numpy_pickle.py:749\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[0;32m    744\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m    746\u001b[0m             \u001b[38;5;66;03m# A memory-mapped array has to be mapped with the endianness\u001b[39;00m\n\u001b[0;32m    747\u001b[0m             \u001b[38;5;66;03m# it has been written with. Other arrays are coerced to the\u001b[39;00m\n\u001b[0;32m    748\u001b[0m             \u001b[38;5;66;03m# native endianness of the host system.\u001b[39;00m\n\u001b[1;32m--> 749\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m                \u001b[49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_native_byte_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidated_mmap_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32m~\\Desktop\\Face_Recognition\\env\\lib\\site-packages\\joblib\\numpy_pickle.py:626\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    624\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 626\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    628\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    633\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    634\u001b[0m         )\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1579\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b625c283-f24e-4ae1-8b08-4a3365a17eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
